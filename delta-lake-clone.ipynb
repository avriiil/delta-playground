{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0313800b-130e-42ec-84ff-a99cfa5ab37f",
   "metadata": {},
   "source": [
    "# Delta Lake Clone - Testing\n",
    "\n",
    "from [the databricks docs](https://docs.databricks.com/en/delta/clone.html#language-python)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc15a30-2ad0-4811-80d2-7b34f71489b3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "825d0546-f3be-4706-a777-9f676381dc76",
   "metadata": {},
   "source": [
    "## write some delta code\n",
    "\n",
    "This code fetches PR and user data from a Github repo (`delta-io/delta`), joins users to PRs and removes duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc418907-ed96-4fc8-b007-9bab44ffdbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lit\n",
    "from delta import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b197a02-5ef8-4c54-b553-c8ca0647e7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception occurred during processing of request from ('127.0.0.1', 55730)\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rpelgrim/miniforge3/envs/pyspark-350-delta-320/lib/python3.11/socketserver.py\", line 317, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/Users/rpelgrim/miniforge3/envs/pyspark-350-delta-320/lib/python3.11/socketserver.py\", line 348, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/Users/rpelgrim/miniforge3/envs/pyspark-350-delta-320/lib/python3.11/socketserver.py\", line 361, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/Users/rpelgrim/miniforge3/envs/pyspark-350-delta-320/lib/python3.11/socketserver.py\", line 755, in __init__\n",
      "    self.handle()\n",
      "  File \"/Users/rpelgrim/miniforge3/envs/pyspark-350-delta-320/lib/python3.11/site-packages/pyspark/accumulators.py\", line 295, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/Users/rpelgrim/miniforge3/envs/pyspark-350-delta-320/lib/python3.11/site-packages/pyspark/accumulators.py\", line 267, in poll\n",
      "    if self.rfile in r and func():\n",
      "                           ^^^^^^\n",
      "  File \"/Users/rpelgrim/miniforge3/envs/pyspark-350-delta-320/lib/python3.11/site-packages/pyspark/accumulators.py\", line 271, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rpelgrim/miniforge3/envs/pyspark-350-delta-320/lib/python3.11/site-packages/pyspark/serializers.py\", line 596, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "builder = SparkSession.builder.master(\"local[4]\").appName(\"parallel\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "323fa95a-207b-4d20-8b30-26e43d67676d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Delta table path\n",
    "delta_table_path = \"/data/github_data\"\n",
    "\n",
    "# Step 1: Fetch data from GitHub API\n",
    "def fetch_github_data():\n",
    "    # GitHub API URL\n",
    "    repo = \"delta-io/delta\"\n",
    "    end_date = datetime.now()\n",
    "    start_date = end_date - timedelta(days=1)\n",
    "    params = {\n",
    "        \"state\": \"all\",\n",
    "        \"since\": start_date.isoformat(),\n",
    "        \"per_page\": 100\n",
    "    }\n",
    "    \n",
    "    prs_url = f\"https://api.github.com/repos/{repo}/pulls\"\n",
    "    prs_response = requests.get(prs_url, params=params)\n",
    "    prs = prs_response.json()\n",
    "    \n",
    "    return prs #, issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5203d886-76d5-4b8c-919e-826c016b9f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "prs = fetch_github_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b87d6a0-3224-41a7-b990-54542f948b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 users made PRs in this timeframe.\n",
      "Unique users: 40\n"
     ]
    }
   ],
   "source": [
    "prs_users = []\n",
    "user_keys = ['login', 'id']\n",
    "\n",
    "for pr in prs:\n",
    "    pr_user = pr['user']\n",
    "    try:\n",
    "        pr_user_sub = {k: pr_user[k] for k in user_keys}\n",
    "    except:\n",
    "        pass\n",
    "    prs_users.append(pr_user_sub)\n",
    "\n",
    "users_df = spark.createDataFrame(prs_users)\n",
    "print(f\"{users_df.count()} users made PRs in this timeframe.\")\n",
    "\n",
    "# Remove duplicates\n",
    "users_df = users_df.dropDuplicates()\n",
    "print(f\"Unique users: {users_df.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "150c7cf6-8b60-4a35-b6f1-f3a1bb9c00ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant fields\n",
    "keys_to_include = ['id', 'number', 'title', 'body']\n",
    "prs_simple = []\n",
    "\n",
    "# iterate over list of prs\n",
    "for pr in prs:\n",
    "    pr_subset = {k: pr[k] for k in keys_to_include}\n",
    "    pr_subset['user_id'] = pr['user']['id']\n",
    "    prs_simple.append(pr_subset)\n",
    "\n",
    "# Create DataFrame\n",
    "prs_df = spark.createDataFrame(prs_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f06c1cb0-fdf4-46e6-99a0-067ef10f74d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+------+--------------------+---------+\n",
      "|                body|        id|number|               title|  user_id|\n",
      "+--------------------+----------+------+--------------------+---------+\n",
      "|#### Which Delta ...|2001658776|  3470|[Spark] Uses java...|  1597914|\n",
      "|<!--\\r\\nThanks fo...|2001644490|  3469|populate Delta cl...|  1174914|\n",
      "|<!--\\r\\nThanks fo...|2001045563|  3467|[Spark] Add Row T...|107926660|\n",
      "|<!--\\r\\nThanks fo...|2000308883|  3466|[Kernel] Configur...|   271029|\n",
      "|#### Which Delta ...|2000227884|  3465|[Spark] Fix Delta...|135709731|\n",
      "|<!--\\r\\nThanks fo...|1999340541|  3464|[WIP][KERNEL][VAR...| 87336575|\n",
      "|Cherry-pick 03bdf...|1998901690|  3463|[3.2 Cherry Pick]...| 59617782|\n",
      "|Cherry-pick 03bdf...|1998901641|  3462|[3.1 Cherry Pick]...| 59617782|\n",
      "|Cherry-pick 03bdf...|1998901548|  3461|[3.0 Cherry Pick]...| 59617782|\n",
      "|<!--\\r\\nThanks fo...|1998456564|  3460|Remove the `setSc...|  1134248|\n",
      "|<!--\\r\\nThanks fo...|1998115737|  3459|[Spark] Support c...|173061829|\n",
      "|#### Which Delta ...|1997975330|  3458|[Spark] Add commi...|   548423|\n",
      "|<!--\\r\\nThanks fo...|1997863204|  3457|[Spark] Block uns...|173061829|\n",
      "|## Description\\r\\...|1997838561|  3456|[Spark] Execute M...|112876214|\n",
      "|<!--\\r\\nThanks fo...|1997396832|  3454|[Spark] Allow sta...|125324092|\n",
      "|<!--\\r\\nThanks fo...|1996871547|  3453|Use correct parti...|  1174914|\n",
      "|<!--\\r\\nThanks fo...|1996814264|  3452|[Spark] Add annot...| 25019163|\n",
      "|<!--\\r\\nThanks fo...|1996721428|  3451|[Spark] Fix Attri...|135709731|\n",
      "|<!--\\r\\nThanks fo...|1996222053|  3449|[Spark] Add RowTr...|107926660|\n",
      "|<!--\\r\\nThanks fo...|1995414829|  3448|[DO_NOT_MERGE] De...| 89107911|\n",
      "+--------------------+----------+------+--------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prs_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9733bdca-c6c9-4517-9549-6bb613ba3301",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = prs_df.alias(\"a\").join(\n",
    "    users_df.alias(\"b\"),\n",
    "    prs_df.user_id == users_df.id,\n",
    "    how = \"left\"\n",
    ").select(\"a.body\", \"a.id\", \"a.number\", \"a.title\", \"a.user_id\", \"b.login\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "499adb96-9adf-4857-8edd-26ce3adae8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Transform data\n",
    "def transform_data(prs):\n",
    "    # Select relevant fields\n",
    "    keys_to_include = ['id', 'number', 'title', 'body']\n",
    "    prs_simple = []\n",
    "\n",
    "    # iterate over list of prs\n",
    "    for pr in prs:\n",
    "        pr_subset = {k: pr[k] for k in keys_to_include}\n",
    "        prs_simple.append(pr_subset)\n",
    "\n",
    "    # Create DataFrame\n",
    "    prs_df = spark.createDataFrame(prs_simple)\n",
    "\n",
    "    # Create DataFrame with usernames and ids\n",
    "    prs_users = []\n",
    "    user_keys = ['login', 'id']\n",
    "    \n",
    "    for pr in prs:\n",
    "        pr_user = pr['user']\n",
    "        try:\n",
    "            pr_user_sub = {k: pr_user[k] for k in user_keys}\n",
    "        except:\n",
    "            pass\n",
    "        prs_users.append(pr_user_sub)\n",
    "\n",
    "    users_df = spark.createDataFrame(prs_users)\n",
    "    print(f\"{users_df.count()} users made PRs in this timeframe.\")\n",
    "    \n",
    "    # Remove duplicates\n",
    "    users_df = users_df.dropDuplicates()\n",
    "    print(f\"Unique users: {users_df.count()}\")\n",
    "    \n",
    "    prs_df = prs_df.dropDuplicates()\n",
    "    \n",
    "    return prs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15f3bad9-d1b1-4bf1-b5dd-22eafcebc9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 users made PRs in this timeframe.\n",
      "Unique users: 40\n"
     ]
    }
   ],
   "source": [
    "prs_df = transform_data(prs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "299e31dd-2fc1-4236-9a4d-2c44f6e179e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+------+--------------------+\n",
      "|                body|        id|number|               title|\n",
      "+--------------------+----------+------+--------------------+\n",
      "|<!--\\r\\nThanks fo...|1999340541|  3464|[WIP][KERNEL][VAR...|\n",
      "|## Description\\r\\...|1994920628|  3446|[Kernel][Clean up...|\n",
      "|#### Which Delta ...|1994302327|  3442|[Spark] Make Conf...|\n",
      "|<!--\\r\\nThanks fo...|1997863204|  3457|[Spark] Block uns...|\n",
      "|## Description\\r\\...|1994406792|  3443|[Spark] Handle ty...|\n",
      "|<!--\\r\\nThanks fo...|2000308883|  3466|[Kernel] Configur...|\n",
      "|#### Which Delta ...|1997975330|  3458|[Spark] Add commi...|\n",
      "|<!--\\r\\nThanks fo...|1996871547|  3453|Use correct parti...|\n",
      "|<!--\\r\\nThanks fo...|1997396832|  3454|[Spark] Allow sta...|\n",
      "|#### Which Delta ...|2001658776|  3470|[Spark] Uses java...|\n",
      "|<!--\\r\\nThanks fo...|1998456564|  3460|Remove the `setSc...|\n",
      "|## Description\\r\\...|1997838561|  3456|[Spark] Execute M...|\n",
      "|Cherry-pick 03bdf...|1998901641|  3462|[3.1 Cherry Pick]...|\n",
      "|<!--\\r\\nThanks fo...|2001644490|  3469|populate Delta cl...|\n",
      "|#### Which Delta ...|2000227884|  3465|[Spark] Fix Delta...|\n",
      "|<!--\\r\\nThanks fo...|1996814264|  3452|[Spark] Add annot...|\n",
      "|Cherry-pick 03bdf...|1998901690|  3463|[3.2 Cherry Pick]...|\n",
      "|<!--\\r\\nThanks fo...|1998115737|  3459|[Spark] Support c...|\n",
      "|Cherry-pick 03bdf...|1998901548|  3461|[3.0 Cherry Pick]...|\n",
      "|<!--\\r\\nThanks fo...|1994759502|  3444|Add DELTA_TESTING...|\n",
      "+--------------------+----------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prs_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "374d5d1d-fed6-4f7a-83c8-8ef99b1c6c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD data to Delta Table\n",
    "prs_df.write.format(\"delta\").mode(\"overwrite\").save(\"data/github_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd569834-2d59-4d45-970e-e494273a4a03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "683e78eb-0549-4f17-adc5-bf2130dc466b",
   "metadata": {},
   "source": [
    "## Clone Delta Lake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36313cd-375a-49b4-ae70-73918fe83a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read Delta Lake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "337f665f-721b-4473-81d8-b85a8d0c4613",
   "metadata": {},
   "outputs": [],
   "source": [
    "from delta.tables import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4559a03c-93e3-46f4-be40-ba897ca763df",
   "metadata": {},
   "outputs": [],
   "source": [
    "deltaTable = DeltaTable.forPath(spark, \"data/github_data/\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e853d7a0-c5d4-4d83-8609-e1dd2a2fea55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/rpelgrim/Documents/git/delta-playground\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18665169-c170-4c82-b67d-9239fb8b47a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[source_table_size: bigint, source_num_of_files: bigint, num_removed_files: bigint, num_copied_files: bigint, removed_files_size: bigint, copied_files_size: bigint]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql('CREATE TABLE delta.`/Users/rpelgrim/Documents/git/delta-playground/data/github_data_clone/` SHALLOW CLONE delta.`/Users/rpelgrim/Documents/git/delta-playground/data/github_data/`')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3865d3-277a-4e13-b04a-8318a2035105",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c2e099-214e-4534-9315-c578c1a11ff8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec5a7ae-603b-49fe-b20b-f7d85f825495",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
